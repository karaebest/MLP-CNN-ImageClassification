{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8Xtkl1xJZhsl"
      },
      "outputs": [],
      "source": [
        "#Given an image, can we predict the correct class of this image?\n",
        "\n",
        "# The images are very small (32x32) and by visualizing them you will notice how difficult it is to distinguish them even for a human.\n",
        "\n",
        "# In this notebook we are going to build a CNN model that can classify images of various objects. We have 10 class of images:\n",
        "\n",
        "# Airplane\n",
        "# Automobile\n",
        "# Bird\n",
        "# Cat\n",
        "# Deer\n",
        "# Dog\n",
        "# Frog\n",
        "# Horse\n",
        "# Ship\n",
        "# Truck\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "htfWUNMlZ6PV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the labels of the dataset\n",
        "labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
        "          'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "# Let's view more images in a grid format\n",
        "# Define the dimensions of the plot grid \n",
        "W_grid = 10\n",
        "L_grid = 10\n",
        "\n",
        "# fig, axes = plt.subplots(L_grid, W_grid)\n",
        "# subplot return the figure object and axes object\n",
        "# we can use the axes object to plot specific figures at various locations\n",
        "\n",
        "fig, axes = plt.subplots(L_grid, W_grid, figsize = (17,17))\n",
        "\n",
        "axes = axes.ravel() # flaten the 15 x 15 matrix into 225 array\n",
        "\n",
        "n_train = len(X_train) # get the length of the train dataset\n",
        "\n",
        "# Select a random number from 0 to n_train\n",
        "for i in np.arange(0, W_grid * L_grid): # create evenly spaces variables \n",
        "\n",
        "    # Select a random number\n",
        "    index = np.random.randint(0, n_train)\n",
        "    # read and display an image with the selected index    \n",
        "    axes[i].imshow(X_train[index,1:])\n",
        "    label_index = int(y_train[index])\n",
        "    axes[i].set_title(labels[label_index], fontsize = 8)\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.subplots_adjust(hspace=0.4)"
      ],
      "metadata": {
        "id": "n24VCQ0xZ_57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the data\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Transform target variable into one-hotencoding\n",
        "y_cat_train = to_categorical(y_train, 10)\n",
        "y_cat_test = to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "JruuUGK0aExT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_cat_train"
      ],
      "metadata": {
        "id": "f2cNWADIaHX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.densenet import DenseNet121\n",
        "\n",
        "# Load pre-trained DenseNet model with frozen convolutional layers\n",
        "base_model = DenseNet121(include_top=False, weights='imagenet', input_shape=(32,32,3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add fully connected layers on top of frozen convolutional layers\n",
        "x = base_model.output\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(256, activation='relu', input_shape=(512,))(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "# Add final classification layer\n",
        "predictions = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Create final model\n",
        "model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "# Print the accuracy\n",
        "accuracy = model.evaluate(x_test, y_test)[1]\n",
        "print(f'Test accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "id": "iw4VyB6vaPuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.densenet import DenseNet121\n",
        "\n",
        "# Load pre-trained DenseNet model with frozen convolutional layers\n",
        "base_model = DenseNet121(include_top=False, weights='imagenet', input_shape=(32,32,3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add fully connected layers on top of frozen convolutional layers\n",
        "x = base_model.output\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(256, activation='relu', input_shape=(512,))(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "# Add final classification layer\n",
        "predictions = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Create final model\n",
        "model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "# Plot the evolution of the accuracy\n",
        "plt.plot(history.history['accuracy'], label='Train accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation accuracy')\n",
        "plt.title('Accuracy evolution during training')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Print the accuracy\n",
        "accuracy = model.evaluate(x_test, y_test)[1]\n",
        "print(f'Test accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "id": "HawLOGULn3OX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.densenet import DenseNet121\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# Load pre-trained DenseNet model with frozen convolutional layers\n",
        "base_model = DenseNet121(include_top=False, weights='imagenet', input_shape=(32,32,3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add fully connected layers on top of frozen convolutional layers\n",
        "x = base_model.output\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(256, activation='relu', input_shape=(512,))(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "# Add final classification layer\n",
        "predictions = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Create final model\n",
        "model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Define the learning rate range\n",
        "lr_range = [0.0001, 0.001, 0.01, 0.1]\n",
        "\n",
        "# Train the model for 10 epochs with different learning rates\n",
        "accuracies = []\n",
        "for lr in lr_range:\n",
        "    model.optimizer.lr = lr\n",
        "    history = model.fit(x_train, y_train, epochs=20, validation_data=(x_test, y_test))\n",
        "    accuracies.append(history.history['val_accuracy'][-1])\n",
        "\n",
        "# Plot the test accuracy vs. the learning rates\n",
        "plt.plot(lr_range, accuracies, 'o-')\n",
        "plt.xscale('log')\n",
        "plt.title('Test accuracy vs. learning rate')\n",
        "plt.xlabel('Learning rate')\n",
        "plt.ylabel('Test accuracy')\n",
        "plt.show()\n",
        "\n",
        "# Print the accuracy\n",
        "accuracy = model.evaluate(x_test, y_test)[1]\n",
        "print(f'Test accuracy: {accuracy}')\n"
      ],
      "metadata": {
        "id": "pBDOdXCgS44Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}